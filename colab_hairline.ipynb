{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hairline Extraction (SAM)\n",
    "Colab에서 헤어라인 윤곽 추출(누끼), 헤어 마스크, 메트릭 산출을 실행합니다.\n",
    "\n",
    "- 입력: 얼굴 정면 사진 1장\n",
    "- 출력: `hair_mask.png`, `hair_cutout.png`, `hair_cutout_rgba.png`, `hairline_mask.png`, `hairline_band.png`, `hairline_band_rgba.png`, `hairline_overlay.png`, `hairline_points.json`, `metrics.json`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "env"},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi || echo 'No GPU'\n",
    "!python --version && pip --version\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "install"},
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip -q install opencv-python-headless>=4.8.0 numpy>=1.24.0 torch torchvision 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "import os, json, cv2, numpy as np, urllib.request\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "download-script"},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hair_assess.py를 Colab 환경에 작성 (동일 로직)\n",
    "hair_assess_code = r'''\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    torch = None  # type: ignore\n",
    "\n",
    "SAM_URLS = {\n",
    "    \"vit_b\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\",\n",
    "}\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_file(url: str, dest_path: str) -> None:\n",
    "    import urllib.request\n",
    "    ensure_dir(str(Path(dest_path).parent))\n",
    "    with urllib.request.urlopen(url) as response, open(dest_path, \"wb\") as out_file:\n",
    "        chunk_size = 1 << 20\n",
    "        while True:\n",
    "            chunk = response.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            out_file.write(chunk)\n",
    "\n",
    "def download_sam_checkpoint(checkpoint_path: str, variant: str = \"vit_b\") -> None:\n",
    "    url = SAM_URLS.get(variant)\n",
    "    if url is None:\n",
    "        raise ValueError(f\"Unsupported SAM variant: {variant}\")\n",
    "    print(f\"[INFO] Downloading SAM {variant} checkpoint to {checkpoint_path} ...\")\n",
    "    download_file(url, checkpoint_path)\n",
    "    print(\"[INFO] Download complete.\")\n",
    "\n",
    "def load_sam_automatic_mask_generator(checkpoint_path: str, device: Optional[str] = None, variant: str = \"vit_b\"):\n",
    "    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "    if device is None:\n",
    "        if torch is not None and torch.cuda.is_available():\n",
    "            device = \"cuda\"\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "    model_type = variant\n",
    "    sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "    sam.to(device)\n",
    "    mask_generator = SamAutomaticMaskGenerator(\n",
    "        model=sam,\n",
    "        points_per_side=16,\n",
    "        pred_iou_thresh=0.86,\n",
    "        stability_score_thresh=0.92,\n",
    "        crop_n_layers=1,\n",
    "        crop_n_points_downscale_factor=2,\n",
    "        min_mask_region_area=300,\n",
    "    )\n",
    "    return mask_generator, device\n",
    "\n",
    "def detect_face_roi(bgr_image: np.ndarray) -> Tuple[Optional[Tuple[int, int, int, int]], Tuple[int, int, int, int]]:\n",
    "    gray = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    cascade_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, flags=cv2.CASCADE_SCALE_IMAGE, minSize=(60, 60))\n",
    "    h, w = gray.shape[:2]\n",
    "    if len(faces) == 0:\n",
    "        face_rect = None\n",
    "        roi_w = int(0.5 * w)\n",
    "        roi_h = int(0.18 * h)\n",
    "        roi_x = max(0, (w - roi_w) // 2)\n",
    "        roi_y = max(0, int(0.12 * h))\n",
    "        top_roi = (roi_x, roi_y, roi_w, roi_h)\n",
    "        return face_rect, top_roi\n",
    "    areas = [fw * fh for (_, _, fw, fh) in faces]\n",
    "    idx = int(np.argmax(areas))\n",
    "    fx, fy, fw, fh = faces[idx]\n",
    "    roi_w = int(fw * 1.2)\n",
    "    roi_h = int(fh * 0.45)\n",
    "    roi_x = max(0, fx + fw // 2 - roi_w // 2)\n",
    "    roi_y = max(0, fy - int(roi_h * 0.9))\n",
    "    roi_x = int(np.clip(roi_x, 0, w - 1))\n",
    "    roi_y = int(np.clip(roi_y, 0, h - 1))\n",
    "    roi_w = int(np.clip(roi_w, 1, w - roi_x))\n",
    "    roi_h = int(np.clip(roi_h, 1, h - roi_y))\n",
    "    return (fx, fy, fw, fh), (roi_x, roi_y, roi_w, roi_h)\n",
    "\n",
    "def compute_mask_score(mask: np.ndarray, top_roi: Tuple[int, int, int, int], face_rect: Optional[Tuple[int, int, int, int]], image_shape: Tuple[int, int, int]) -> float:\n",
    "    h, w = image_shape[:2]\n",
    "    x, y, rw, rh = top_roi\n",
    "    mask_bool = mask.astype(bool)\n",
    "    top_mask = np.zeros((h, w), dtype=bool)\n",
    "    top_mask[y : y + rh, x : x + rw] = True\n",
    "    top_overlap = (mask_bool & top_mask).sum()\n",
    "    top_fraction = top_overlap / (rw * rh + 1e-6)\n",
    "    face_penalty = 0.0\n",
    "    if face_rect is not None:\n",
    "        fx, fy, fw, fh = face_rect\n",
    "        face_mask = np.zeros((h, w), dtype=bool)\n",
    "        face_mask[fy : fy + fh, fx : fx + fw] = True\n",
    "        face_overlap = (mask_bool & face_mask).sum()\n",
    "        face_fraction = face_overlap / (fw * fh + 1e-6)\n",
    "        face_penalty = 0.6 * face_fraction\n",
    "    area_fraction = mask_bool.sum() / (h * w + 1e-6)\n",
    "    area_score = 1.0 - abs(area_fraction - 0.16) / 0.16\n",
    "    area_score = float(np.clip(area_score, 0.0, 1.0))\n",
    "    spatial_bonus = 0.0\n",
    "    if face_rect is not None:\n",
    "        fx, fy, fw, fh = face_rect\n",
    "        face_cx = fx + fw / 2.0\n",
    "        mask_coords = np.column_stack(np.nonzero(mask_bool))\n",
    "        if mask_coords.size > 0:\n",
    "            mask_cy, mask_cx = mask_coords.mean(axis=0)\n",
    "            dx = abs(mask_cx - face_cx) / (w + 1e-6)\n",
    "            spatial_bonus = float(1.0 - np.clip(dx / 0.25, 0.0, 1.0)) * 0.3\n",
    "    score = (1.2 * top_fraction) + (0.6 * area_score) + spatial_bonus - face_penalty\n",
    "    return float(score)\n",
    "\n",
    "def select_hair_mask(masks: list, image_rgb: np.ndarray, top_roi, face_rect) -> Optional[np.ndarray]:\n",
    "    if not masks:\n",
    "        return None\n",
    "    h, w = image_rgb.shape[:2]\n",
    "    best_score = -1e9\n",
    "    best_mask = None\n",
    "    for m in masks:\n",
    "        seg = m.get(\"segmentation\")\n",
    "        if seg is None:\n",
    "            continue\n",
    "        score = compute_mask_score(seg.astype(np.uint8), top_roi, face_rect, (h, w, 3))\n",
    "        score += 0.2 * float(m.get(\"predicted_iou\", 0.0))\n",
    "        score += 0.2 * float(m.get(\"stability_score\", 0.0))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_mask = seg.astype(np.uint8)\n",
    "    return best_mask\n",
    "\n",
    "def compute_metrics(hair_mask: np.ndarray, face_rect: Optional[Tuple[int, int, int, int]], top_roi: Tuple[int, int, int, int]) -> Dict[str, float]:\n",
    "    h, w = hair_mask.shape[:2]\n",
    "    mask = (hair_mask > 0).astype(np.uint8)\n",
    "    if face_rect is not None:\n",
    "        fx, fy, fw, fh = face_rect\n",
    "        cx = fx + fw // 2\n",
    "    else:\n",
    "        cx = w // 2\n",
    "    left_mask = mask[:, :cx]\n",
    "    right_mask = mask[:, cx:]\n",
    "    left_area = float(left_mask.sum())\n",
    "    right_area = float(right_mask.sum())\n",
    "    left_density = left_area / (h * max(cx, 1))\n",
    "    right_density = right_area / (h * max(w - cx, 1))\n",
    "    asymmetry_index = abs(left_density - right_density) / (max((left_density + right_density) / 2.0, 1e-6))\n",
    "    tx, ty, tw, th = top_roi\n",
    "    top_mask = mask[ty : ty + th, tx : tx + tw]\n",
    "    coverage_top = float(top_mask.sum()) / (tw * th + 1e-6)\n",
    "    third = max(tw // 3, 1)\n",
    "    left_top = top_mask[:, :third]\n",
    "    center_top = top_mask[:, third : 2 * third]\n",
    "    right_top = top_mask[:, 2 * third :]\n",
    "    left_cov = float(left_top.sum()) / (left_top.size + 1e-6)\n",
    "    center_cov = float(center_top.sum()) / (center_top.size + 1e-6)\n",
    "    right_cov = float(right_top.sum()) / (right_top.size + 1e-6)\n",
    "    corner_cov = (left_cov + right_cov) / 2.0\n",
    "    corner_deficit = max(0.0, center_cov - corner_cov)\n",
    "    risk = 0.5 * max(0.0, (0.5 - coverage_top) / 0.5) + 0.3 * min(1.0, corner_deficit / 0.3) + 0.2 * min(1.0, asymmetry_index / 0.3)\n",
    "    risk = float(np.clip(risk, 0.0, 1.0))\n",
    "    return {\n",
    "        \"coverage_top\": float(coverage_top),\n",
    "        \"left_density\": float(left_density),\n",
    "        \"right_density\": float(right_density),\n",
    "        \"asymmetry_index\": float(asymmetry_index),\n",
    "        \"corner_deficit\": float(corner_deficit),\n",
    "        \"risk_score\": float(risk),\n",
    "    }\n",
    "\n",
    "def visualize_and_save_outputs(out_dir: str, bgr: np.ndarray, hair_mask: Optional[np.ndarray], metrics: Dict[str, float]) -> None:\n",
    "    ensure_dir(out_dir)\n",
    "    base = Path(out_dir)\n",
    "    cv2.imwrite(str(base / \"input.jpg\"), bgr)\n",
    "    if hair_mask is None:\n",
    "        with open(base / \"metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\"error\": \"no_hair_mask\", \"metrics\": metrics}, f, ensure_ascii=False, indent=2)\n",
    "        return\n",
    "    mask_u8 = (hair_mask > 0).astype(np.uint8) * 255\n",
    "    cv2.imwrite(str(base / \"hair_mask.png\"), mask_u8)\n",
    "    cutout = cv2.bitwise_and(bgr, bgr, mask=mask_u8)\n",
    "    cv2.imwrite(str(base / \"hair_cutout.png\"), cutout)\n",
    "    b, g, r = cv2.split(bgr)\n",
    "    rgba = cv2.merge((b, g, r, mask_u8))\n",
    "    cv2.imwrite(str(base / \"hair_cutout_rgba.png\"), rgba)\n",
    "    contours, _ = cv2.findContours((mask_u8 > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    overlay = bgr.copy()\n",
    "    cv2.drawContours(overlay, contours, -1, (0, 255, 0), thickness=2)\n",
    "    blended = cv2.addWeighted(overlay, 0.35, bgr, 0.65, 0)\n",
    "    cv2.imwrite(str(base / \"overlay.png\"), blended)\n",
    "    with open(base / \"metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def extract_hairline_polyline(hair_mask: np.ndarray, top_roi: Tuple[int, int, int, int]) -> Optional[np.ndarray]:\n",
    "    x, y, w, h = top_roi\n",
    "    if w <= 2 or h <= 2:\n",
    "        return None\n",
    "    roi = (hair_mask[y : y + h, x : x + w] > 0)\n",
    "    hR, wR = roi.shape[:2]\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for col in range(wR):\n",
    "        col_data = roi[:, col]\n",
    "        idxs = np.flatnonzero(col_data[::-1])\n",
    "        if idxs.size == 0:\n",
    "            ys.append(np.nan)\n",
    "            xs.append(col)\n",
    "        else:\n",
    "            y_rel_from_bottom = int(idxs[0])\n",
    "            y_rel = (hR - 1) - y_rel_from_bottom\n",
    "            ys.append(float(y_rel))\n",
    "            xs.append(col)\n",
    "    xs_arr = np.asarray(xs)\n",
    "    ys_arr = np.asarray(ys, dtype=float)\n",
    "    valid = ~np.isnan(ys_arr)\n",
    "    segments = []\n",
    "    start = None\n",
    "    for i, v in enumerate(valid):\n",
    "        if v and start is None:\n",
    "            start = i\n",
    "        elif (not v) and (start is not None):\n",
    "            segments.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        segments.append((start, wR - 1))\n",
    "    if not segments:\n",
    "        return None\n",
    "    mid = wR // 2\n",
    "    def seg_key(seg):\n",
    "        s, e = seg\n",
    "        crosses_mid = 1 if (s <= mid <= e) else 0\n",
    "        length = e - s + 1\n",
    "        center_dist = -abs(((s + e) // 2) - mid)\n",
    "        return (crosses_mid, length, center_dist)\n",
    "    s, e = max(segments, key=seg_key)\n",
    "    xs_seg = xs_arr[s : e + 1]\n",
    "    ys_seg = ys_arr[s : e + 1]\n",
    "    k = min(11, max(3, (len(xs_seg) // 10) * 2 + 1))\n",
    "    k = max(3, k if k % 2 == 1 else k - 1)\n",
    "    if len(xs_seg) >= k:\n",
    "        pad = k // 2\n",
    "        ys_pad = np.pad(ys_seg, (pad, pad), mode=\"edge\")\n",
    "        kernel = np.ones(k, dtype=float) / float(k)\n",
    "        ys_smooth = np.convolve(ys_pad, kernel, mode=\"valid\")\n",
    "    else:\n",
    "        ys_smooth = ys_seg\n",
    "    pts = np.column_stack([xs_seg + x, ys_smooth + y]).astype(np.int32)\n",
    "    if pts.shape[0] < 2:\n",
    "        return None\n",
    "    return pts\n",
    "\n",
    "def save_hairline_outputs(base_dir: str, bgr: np.ndarray, hair_mask: np.ndarray, top_roi: Tuple[int, int, int, int], hairline_pts: Optional[np.ndarray]) -> None:\n",
    "    base = Path(base_dir)\n",
    "    if hairline_pts is None:\n",
    "        return\n",
    "    pts_list = [{\"x\": int(p[0]), \"y\": int(p[1])} for p in hairline_pts.tolist()]\n",
    "    with open(base / \"hairline_points.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"top_roi\": {\"x\": top_roi[0], \"y\": top_roi[1], \"w\": top_roi[2], \"h\": top_roi[3]}, \"points\": pts_list}, f, ensure_ascii=False, indent=2)\n",
    "    h, w = hair_mask.shape[:2]\n",
    "    thin = np.zeros((h, w), dtype=np.uint8)\n",
    "    band = np.zeros((h, w), dtype=np.uint8)\n",
    "    cv2.polylines(thin, [hairline_pts], isClosed=False, color=255, thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.polylines(band, [hairline_pts], isClosed=False, color=255, thickness=6, lineType=cv2.LINE_AA)\n",
    "    band = cv2.bitwise_and(band, (hair_mask > 0).astype(np.uint8) * 255)\n",
    "    cv2.imwrite(str(base / \"hairline_mask.png\"), thin)\n",
    "    cv2.imwrite(str(base / \"hairline_band.png\"), band)\n",
    "    b_ch, g_ch, r_ch = cv2.split(bgr)\n",
    "    band_rgba = cv2.merge((b_ch, g_ch, r_ch, band))\n",
    "    cv2.imwrite(str(base / \"hairline_band_rgba.png\"), band_rgba)\n",
    "    hairline_cutout = cv2.bitwise_and(bgr, bgr, mask=band)\n",
    "    cv2.imwrite(str(base / \"hairline_cutout.png\"), hairline_cutout)\n",
    "    overlay = bgr.copy()\n",
    "    cv2.polylines(overlay, [hairline_pts], isClosed=False, color=(0, 0, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    blended = cv2.addWeighted(overlay, 0.5, bgr, 0.5, 0)\n",
    "    cv2.imwrite(str(base / \"hairline_overlay.png\"), blended)\n",
    "\n",
    "def run(image_path: str, output_dir: str, sam_checkpoint: str, variant: str = \"vit_b\", device: Optional[str] = None, force_download: bool = False) -> None:\n",
    "    if not os.path.isfile(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise RuntimeError(f\"Failed to read image: {image_path}\")\n",
    "    face_rect, top_roi = detect_face_roi(bgr)\n",
    "    if force_download or (not os.path.isfile(sam_checkpoint)):\n",
    "        ensure_dir(str(Path(sam_checkpoint).parent))\n",
    "        download_sam_checkpoint(sam_checkpoint, variant)\n",
    "    mask_generator, device_used = load_sam_automatic_mask_generator(sam_checkpoint, device=device, variant=variant)\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    masks = mask_generator.generate(rgb)\n",
    "    hair_mask = select_hair_mask(masks, rgb, top_roi, face_rect)\n",
    "    hairline_pts = None\n",
    "    if hair_mask is not None:\n",
    "        try:\n",
    "            hairline_pts = extract_hairline_polyline(hair_mask.astype(np.uint8), top_roi)\n",
    "        except Exception:\n",
    "            hairline_pts = None\n",
    "    metrics = compute_metrics(hair_mask if hair_mask is not None else np.zeros(rgb.shape[:2], dtype=np.uint8), face_rect, top_roi)\n",
    "    visualize_and_save_outputs(output_dir, bgr, hair_mask, metrics)\n",
    "    if hair_mask is not None:\n",
    "        save_hairline_outputs(output_dir, bgr, hair_mask.astype(np.uint8), top_roi, hairline_pts)\n",
    "    print(\"[OK] Outputs saved to:\", output_dir)\n",
    "    print(json.dumps(metrics, ensure_ascii=False, indent=2))\n",
    "\n",
    "def parse_args(argv=None):\n",
    "    p = argparse.ArgumentParser(description=\"Hairline extraction in Colab\")\n",
    "    p.add_argument(\"--image\", required=True)\n",
    "    p.add_argument(\"--output-dir\", default=\"outputs\")\n",
    "    p.add_argument(\"--sam-checkpoint\", default=str(Path(\"weights\") / \"sam_vit_b_01ec64.pth\"))\n",
    "    p.add_argument(\"--variant\", default=\"vit_b\", choices=[\"vit_b\"])\n",
    "    p.add_argument(\"--device\", default=None, choices=[\"cpu\", \"cuda\", None])\n",
    "    p.add_argument(\"--download\", action=\"store_true\")\n",
    "    return p.parse_args(argv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    run(args.image, args.output_dir, args.sam_checkpoint, args.variant, args.device, args.download)\n",
    "'''\n",
    "open('hair_assess_colab.py', 'w', encoding='utf-8').write(hair_assess_code)\n",
    "print('[OK] hair_assess_colab.py created')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "upload"},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 입력 이미지 업로드\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "# 업로드한 파일 이름 중 첫 번째를 사용\n",
    "IMAGE = list(uploaded.keys())[0]\n",
    "print('Using image:', IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "run"},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 실행: SAM 체크포인트 자동 다운로드\n",
    "!python hair_assess_colab.py --image "$IMAGE" --output-dir outputs --device cuda --download || \\\n",
    "python hair_assess_colab.py --image "$IMAGE" --output-dir outputs --device cpu --download\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {"id": "visualize"},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import JSON, display\n",
    "import json\n",
    "def imshow(path):\n",
    "    import matplotlib.image as mpimg\n",
    "    img = mpimg.imread(path)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(path)\n",
    "    plt.show()\n",
    "base = Path('outputs')\n",
    "for name in ['input.jpg','hair_mask.png','hair_cutout.png','hair_cutout_rgba.png','hairline_mask.png','hairline_band.png','hairline_band_rgba.png','hairline_overlay.png']:\n",
    "    p = base / name\n",
    "    if p.exists():\n",
    "        imshow(str(p))\n",
    "metrics_path = base / 'metrics.json'\n",
    "if metrics_path.exists():\n",
    "    display(JSON(json.load(open(metrics_path, 'r', encoding='utf-8'))))\n",
    "pts_path = base / 'hairline_points.json'\n",
    "if pts_path.exists():\n",
    "    display(JSON(json.load(open(pts_path, 'r', encoding='utf-8'))))\n"
   ]
  }
 ]
}
